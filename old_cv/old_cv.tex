\documentclass[10pt, letterpaper]{article}
% Packages:
\usepackage[
    ignoreheadfoot, % set margins without considering header and footer
    top=1 cm, % seperation between body and page edge from the top
    bottom=1.5 cm, % seperation between body and page edge from the bottom
    left=1.5 cm, % seperation between body and page edge from the left
    right=1.5 cm, % seperation between body and page edge from the right
    footskip=1.0 cm, % seperation between body and footer
    % showframe % for debugging 
]{geometry} % for adjusting page geometry
\usepackage{titlesec} % for customizing section titles
\usepackage{tabularx} % for making tables with fixed width columns
\usepackage{array} % tabularx requires this
\usepackage[dvipsnames]{xcolor} % for coloring text
\definecolor{primaryColor}{RGB}{0, 79, 144} % define primary color
\usepackage{enumitem} % for customizing lists
\usepackage{fontawesome5} % for using icons
\usepackage{amsmath} % for math
\usepackage[
    pdftitle={Allan Zhang's CV},
    pdfauthor={Allan Zhang},
    pdfcreator={LaTeX with RenderCV},
    colorlinks=true,
    urlcolor=primaryColor
]{hyperref} % for links, metadata and bookmarks
\usepackage[pscoord]{eso-pic} % for floating text on the page
\usepackage{calc} % for calculating lengths
\usepackage{bookmark} % for bookmarks
\usepackage{lastpage} % for getting the total number of pages
\usepackage{changepage} % for one column entries (adjustwidth environment)
\usepackage{paracol} % for two and three column entries
\usepackage{ifthen} % for conditional statements
\usepackage{needspace} % for avoiding page brake right after the section title
\usepackage{iftex} % check if engine is pdflatex, xetex or luatex

% Ensure that generate pdf is machine readable/ATS parsable:
\ifPDFTeX
    \input{glyphtounicode}
    \pdfgentounicode=1
    % \usepackage[T1]{fontenc} % this breaks sb2nov
    \usepackage[utf8]{inputenc}
    \usepackage{lmodern}
\fi



% Some settings:
\AtBeginEnvironment{adjustwidth}{\partopsep0pt} % remove space before adjustwidth environment
\pagestyle{empty} % no header or footer
\setcounter{secnumdepth}{0} % no section numbering
\setlength{\parindent}{0pt} % no indentation
\setlength{\topskip}{0pt} % no top skip
\setlength{\columnsep}{0cm} % set column seperation
\makeatletter
\let\ps@customFooterStyle\ps@plain % Copy the plain style to customFooterStyle
\patchcmd{\ps@customFooterStyle}{\thepage}{
    \color{gray}\textit{\small Allan Zhang - Page \thepage{} of \pageref*{LastPage}}
}{}{} % replace number by desired string
\makeatother
\pagestyle{customFooterStyle}

\titleformat{\section}{\needspace{4\baselineskip}\bfseries\large}{}{0pt}{}[\vspace{1pt}\titlerule]

\titlespacing{\section}{
    % left space:
    -1pt
}{
    % top space:
    0.3 cm
}{
    % bottom space:
    0.2 cm
} % section title spacing

\renewcommand\labelitemi{$\circ$} % custom bullet points
\newenvironment{highlights}{
    \begin{itemize}[
        topsep=0.10 cm,
        parsep=0.10 cm,
        partopsep=0pt,
        itemsep=0pt,
        leftmargin=0.4 cm + 10pt
    ]
}{
    \end{itemize}
} % new environment for highlights

\newenvironment{highlightsforbulletentries}{
    \begin{itemize}[
        topsep=0.10 cm,
        parsep=0.10 cm,
        partopsep=0pt,
        itemsep=0pt,
        leftmargin=10pt
    ]
}{
    \end{itemize}
} % new environment for highlights for bullet entries


\newenvironment{onecolentry}{
    \begin{adjustwidth}{
        0.2 cm + 0.00001 cm
    }{
        0.2 cm + 0.00001 cm
    }
}{
    \end{adjustwidth}
} % new environment for one column entries

\newenvironment{twocolentry}[2][]{
    \onecolentry
    \def\secondColumn{#2}
    \setcolumnwidth{\fill, 4.5 cm}
    \begin{paracol}{2}
}{
    \switchcolumn \raggedleft \secondColumn
    \end{paracol}
    \endonecolentry
} % new environment for two column entries

\newenvironment{header}{
    \setlength{\topsep}{0pt}\par\kern\topsep\centering\linespread{1.5}
}{
    \par\kern\topsep
} % new environment for the header

\newcommand{\placelastupdatedtext}{% \placetextbox{<horizontal pos>}{<vertical pos>}{<stuff>}
  \AddToShipoutPictureFG*{% Add <stuff> to current page foreground
    \put(
        \LenToUnit{\paperwidth-2 cm-0.2 cm+0.05cm},
        \LenToUnit{\paperheight-1.0 cm}
    ){\vtop{{\null}\makebox[0pt][c]{
        \small\color{gray}\textit{Last updated in January 2025}\hspace{\widthof{Last updated in January 2025}}
    }}}%
  }%
}%



% save the original href command in a new command:
\let\hrefWithoutArrow\href

% new command for external links:
\renewcommand{\href}[2]{\hrefWithoutArrow{#1}{\ifthenelse{\equal{#2}{}}{ }{#2 }\raisebox{.15ex}{\footnotesize \faExternalLink*}}}


\begin{document}
    \newcommand{\AND}{\unskip
        \cleaders\copy\ANDbox\hskip\wd\ANDbox
        \ignorespaces
    }
    \newsavebox\ANDbox
    \sbox\ANDbox{}

    \placelastupdatedtext
    \begin{header}
        \textbf{\fontsize{24 pt}{24 pt}\selectfont Allan Zhang}

        \vspace{0.3 cm}

        \normalsize
        \mbox{{\color{black}\footnotesize\faMapMarker*}\hspace*{0.13cm}Los Angeles, CA}%
        \kern 0.25 cm%
        \AND%
        \kern 0.25 cm%
        \mbox{\hrefWithoutArrow{mailto:allanzhang440@gmail.com}{\color{black}{\footnotesize\faEnvelope[regular]}\hspace*{0.13cm}allanzhang440@gmail.com}}%
        \kern 0.25 cm%
        \AND%
        \kern 0.25 cm%

        \mbox{\hrefWithoutArrow{tel:+90-541-999-99-99}{\color{black}{\footnotesize\faPhone*}\hspace*{0.13cm}609-943-8429}}%
        \kern 0.25 cm%
        \AND%
        \kern 0.25 cm%
        \mbox{\hrefWithoutArrow{https://giyushino.github.io/}{\color{black}{\footnotesize\faLink}\hspace*{0.13cm}https://giyushino.github.io}}%
        \kern 0.25 cm%
        \AND%
        \kern 0.25 cm%        %\mbox{\hrefWithoutArrow{https://www.linkedin.com/in/allan-zhang-928a6431a}{\color{black}{\footnotesize\faLinkedinIn}\hspace*{0.13cm}Allan Zhang}}%
        %\kern 0.25 cm%
        %\AND%
        %\kern 0.25 cm%
        \mbox{\hrefWithoutArrow{https://github.com/giyushino}{\color{black}{\footnotesize\faGithub}\hspace*{0.13cm}giyushino}}%
    \end{header}

    \vspace{0.3 cm - 0.3 cm}

    \section{Education}



        
        \begin{twocolentry}{
            
            
        \textit{Sept 2024 – June 2028}}
            \textbf{University of California, Los Angeles}

            \textit{BS in Applied Mathematics}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item GPA: 4.00 %(\href{https://example.com}{a link to somewhere})
                \item \textbf{Relevant Coursework:}  Multivariable Calculus, Linear Algebra, Discrete Structures, Intro to C++ \\ (Math 32A, Math 32B, Math 33A, Math 61A, CS 31)
            \end{highlights}
        \end{onecolentry}

    \section{Experience}
        \begin{twocolentry}{
        \textit{Los Angeles, CA}    
            
        \textit{Nov 2024 – Present}}
            \textbf{Undergraduate Research Assistant $|$ BigML}
            
            \textit{UCLA}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item{Aided PhD student Siddharth Joshi in training and evaulate custom, lightweight VLMs on spatial reasoning tasks, attemping to understand where and why model fails. Findings allow us to work on creating optimal, high-quality datasets to improve performance}
                \item{Wrote functions to create highly modular datasets, testing the effects of modality mismatch, spurious correlations, alignment between visual and textual context, and number of unique images per class on model's performance}
                \item{Utilizing mechanistic interpretability techniques, used hooks to extract each layer's activation patterns, as well as the model's predictions during each layer. Created heatmaps using Seaborn to visualize how data is processed throughout the model}
                \item{Used custom linear probes to determine if tensors passed through model still retained spatial information, specifically testing the tensors passed through the multimodal projector}
            \end{highlights}
        \end{onecolentry}
    
    \section{Projects}
           \vspace{0.2 cm}

        \begin{twocolentry}{
            
            
        \textit{\href{https://github.com/giyushino/tinyMathLLM}{TinyMathLLM}}}
        \textbf{TinyMathLLM}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
            \item{Tested different methods of training and fine-tuning small, opensource models to create lightweight math chabots that can run locally. Attempted to see if model could learn to do math from question + answer dataset. Also tested if model could learn to extract important values from questions and classify problem types, allowing it to be implemented into a math agent}
            \item{Trained TinyLlama (1.1B param) on both strategies using 4bit-quanitzation + low-rank adaption, as well as built-in Transformers training loop. Wrote custom LORA implementation from scratch to speed up inference}
            \item{Created custom datasets for both use cases, including 100k+ example user inputs + model responses. Used Deepkseek-chat as judge to guage model performance}
            \end{highlights}
        \end{onecolentry}     
        \vspace{0.2cm}

        \begin{twocolentry}{
        \textit{\href{https://github.com/giyushino/MyOwnDoodleGuesser}{MyOwnDoogleGuesser}}}
            \textbf{Doodle Guesser}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
            \item{Fine-tuned vision transformer (CLIP-Vit-Large-Patch-14) on 6 different animal drawings. Collected and processed 1,000,000+ images from 6 classes to create custom dataset. After training, accuracy increased from 54$\%$ to 87$\%$. Worst group accuracy increased from 39$\%$ to 76$\%$}
            \item{Created CLIP model from scratch using PyTorch. Wrote custom tokenizer and encoders to embed input labels and images into multi-dimensional vectors. Acheived 70$\%$ accuracy after only being trained of a subset of the previous dataset (200,000 images)}
            \item{Created GUI using Pygame to allow users to draw on a canvas. After drawing, screenshot was taken, processed, and fed into model, softmax taken of the outputted logits to predict the most likely class}
            \end{highlights}
        \end{onecolentry}


        \vspace{0.2 cm}

        \begin{twocolentry}{
            
            
        \textit{\href{https://github.com/giyushino/whatToEatAtUCLA}{What2Eat@UCLA}}}
        \textbf{UCLA Dining Assistant}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
            \item{Using OpenAI API and Deepseek-chat, created chatbot that recommends UCLA dining halls based on student preferences. Real time data about dining halls menus and hours was scraped from UCLA Dining website and processed using BeautifulSoup}
            \item{Deepeek was fed with data about each dining hall, including menu + nutrional information for each item. Taking into account user's flavor/cuisines preferences, dietary restrictions, and other criteria, chatbot would recommend dining halls}
            \item{Currently fine-tuning small, opensource model on example chat data to improve performance and remove reliance on OpenAI. Model can be run locally using 4-bit quanitzation}
            \end{highlights}
        \end{onecolentry}


        \vspace{0.2 cm}
        \begin{twocolentry}{
            
            
        \textit{\href{https://github.com/giyushino/clip-vit-large-patch14-batch}{Fine-Tuning Functions}}}
            \textbf{Efficient Finetuning Pipeline}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item Wrote functions to efficiently fine-tune and evaluate models on weak GPUs or CPU. Functions focused on batching images fed into model to reduce VRAM requirements and preventing Google Colab from crashing
                \item Tested on OpenAI's CLIP-Vit-Large-Patch-14 model using CIFAR-10 dataset. Using built-in training functions from Hugging Face caused Google Colab to crash, custom functions did not. Saw 5\% improvement in accuracy (91\% $\rightarrow$ 96\%) with limited training data, computational power, and time. To prevent overfitting, wrote new function to shuffle training dataset for every epoch
                \item Tools Used: Python, PyTorch, Google Colab, Hugging Face
            \end{highlights}
        \end{onecolentry}

  
 
    \section{Skills}
        
        \begin{onecolentry}
            \textbf{Programming Languages and Frameworks:} Python, PyTorch, NumPy, Matplotlib, TensorFlow, scikit-learn,  OpenCV, Hugging Face, \LaTeX, C++ (basic)%, HTML (basic), CSS (basic), Bash, Git
        \end{onecolentry}

        \vspace{0.2 cm}

        \begin{onecolentry}
            \textbf{Languages:} English, Korean
        \end{onecolentry}

        \vspace{0.2 cm}


\end{document}


        \begin{twocolentry}{
            
        \textit{\href{https://github.com/giyushino/UCLABathroom}{UCLA Bathroom}}}
            \textbf{Bathroom Usage Prediction}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item Implemented linear regression model from scratch in Python to predict how many people are using the
                Rieber Hall 7N men’s bathroom based on time and day. Wrote the cost, gradient, and gradient descent
                functions only using NumPy
                \item Tools used: Python, NumPy, Matplotlib
            \end{highlights}
        \end{onecolentry}


   \vspace{0.2 cm}

        \begin{twocolentry}{
            
            
        \textit{\href{https://github.com/giyushino/hand-detection}{Drone Control}}}
            \textbf{Hand-Controlled Drone}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item Created and labeled dataset consisting of 400+ images of hands pointing up, down, left, right, backwards, and forwards. Trained YOLOv8 model with the data and utilized OpenCV to detect directions
                real time. Fed real-time collected information to FPV drone’s flight computer to control movement
                \item Tools Used: Python, OpenCV, YOLOv8 
            \end{highlights}
        \end{onecolentry}



        \vspace{0.2 cm}
        
        \begin{twocolentry}{
            
            
        \textit{July 2024 - Present}}
            \textbf{Self Study}

            \textit{Machine Learning and Data Science}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item \textbf{Textbooks:}  \textit {Reinforcement Learning:
An Introduction}, \textit {An Introduction to Statistical Learning with Applications in Python}, \textit{Dive into Deep Learning} 
            \item 
            \textbf{Courses:}  Andrew Ng's Machine Learning Specialization

            \end{highlights}
        \end{onecolentry}

   
     
        \vspace{0.2 cm}
        \begin{twocolentry}{
           
        \textit{Work in Progress}}
            \textbf{Flappy Bird AI}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item Created own version of Flappy Bird in Python using Pygame. Currently creating neural network that utilizes Q-learning to learn to play the game. Game state is collected at every frame is collected and fed into model, including bird’s vertical position, vertical velocity, and distance from both pipes
                \item Tools used: Python, PyTorch, Pygame
            \end{highlights}
        \end{onecolentry}

        \vspace{0.2 cm}
        \begin{twocolentry}{
            
        \textit{2020 - 2021}}
            \textbf{Self Published Novel}
        \end{twocolentry}

        \vspace{0.10 cm}
        \begin{onecolentry}
            \begin{highlights}
                \item Wrote a 45,000 word novel,  published it online. Amassed 272,000 reads, 7,000 comments, and 6,200 reviews. Reviewed other authors' works,  providing grammatical advice
            \end{highlights}
        \end{onecolentry}



